{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f592b7e",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# 自动微分\n",
    ":label:`sec_autograd`\n",
    "\n",
    "正如 :numref:`sec_calculus`中所说，求导是几乎所有深度学习优化算法的关键步骤。\n",
    "虽然求导的计算很简单，只需要一些基本的微积分。\n",
    "但对于复杂的模型，手工进行更新是一件很痛苦的事情（而且经常容易出错）。\n",
    "\n",
    "深度学习框架通过自动计算导数，即*自动微分*（automatic differentiation）来加快求导。\n",
    "实际中，根据设计好的模型，系统会构建一个*计算图*（computational graph），\n",
    "来跟踪计算是哪些数据通过哪些操作组合起来产生输出。\n",
    "自动微分使系统能够随后反向传播梯度。\n",
    "这里，*反向传播*（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。\n",
    "\n",
    "## 一个简单的例子\n",
    "\n",
    "作为一个演示例子，(**假设我们想对函数$y=2\\mathbf{x}^{\\top}\\mathbf{x}$关于列向量$\\mathbf{x}$求导**)。\n",
    "首先，我们创建变量`x`并为其分配一个初始值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "498c3ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:09.704166Z",
     "iopub.status.busy": "2022-12-07T16:37:09.703482Z",
     "iopub.status.idle": "2022-12-07T16:37:10.849947Z",
     "shell.execute_reply": "2022-12-07T16:37:10.848845Z"
    },
    "origin_pos": 2,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee187726",
   "metadata": {
    "origin_pos": 5
   },
   "source": [
    "[**在我们计算$y$关于$\\mathbf{x}$的梯度之前，需要一个地方来存储梯度。**]\n",
    "重要的是，我们不会在每次对一个参数求导时都分配新的内存。\n",
    "因为我们经常会成千上万次地更新相同的参数，每次都分配新的内存可能很快就会将内存耗尽。\n",
    "注意，一个标量函数关于向量$\\mathbf{x}$的梯度是向量，并且与$\\mathbf{x}$具有相同的形状。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8f4026b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.853801Z",
     "iopub.status.busy": "2022-12-07T16:37:10.853279Z",
     "iopub.status.idle": "2022-12-07T16:37:10.858081Z",
     "shell.execute_reply": "2022-12-07T16:37:10.857050Z"
    },
    "origin_pos": 7,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "x.requires_grad_(True)  # 等价于x=torch.arange(4.0,requires_grad=True)\n",
    "x.grad  # 默认值是None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd755d2",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "(**现在计算$y$。**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb79797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.861469Z",
     "iopub.status.busy": "2022-12-07T16:37:10.861031Z",
     "iopub.status.idle": "2022-12-07T16:37:10.867917Z",
     "shell.execute_reply": "2022-12-07T16:37:10.867083Z"
    },
    "origin_pos": 12,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = 2 * torch.dot(x, x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614f1281",
   "metadata": {
    "origin_pos": 15
   },
   "source": [
    "`x`是一个长度为4的向量，计算`x`和`x`的点积，得到了我们赋值给`y`的标量输出。\n",
    "接下来，[**通过调用反向传播函数来自动计算`y`关于`x`每个分量的梯度**]，并打印这些梯度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b21e1420",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.872410Z",
     "iopub.status.busy": "2022-12-07T16:37:10.871742Z",
     "iopub.status.idle": "2022-12-07T16:37:10.877373Z",
     "shell.execute_reply": "2022-12-07T16:37:10.876674Z"
    },
    "origin_pos": 17,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892b1d5",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "函数$y=2\\mathbf{x}^{\\top}\\mathbf{x}$关于$\\mathbf{x}$的梯度应为$4\\mathbf{x}$。\n",
    "让我们快速验证这个梯度是否计算正确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f72da1f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.880808Z",
     "iopub.status.busy": "2022-12-07T16:37:10.880315Z",
     "iopub.status.idle": "2022-12-07T16:37:10.887007Z",
     "shell.execute_reply": "2022-12-07T16:37:10.886236Z"
    },
    "origin_pos": 22,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad == 4 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355dc4bd",
   "metadata": {
    "origin_pos": 25
   },
   "source": [
    "[**现在计算`x`的另一个函数。**]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e18e98cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.890349Z",
     "iopub.status.busy": "2022-12-07T16:37:10.889853Z",
     "iopub.status.idle": "2022-12-07T16:37:10.895860Z",
     "shell.execute_reply": "2022-12-07T16:37:10.895107Z"
    },
    "origin_pos": 27,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值\n",
    "x.grad.zero_()\n",
    "y = x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02fbf714",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/root/workspace/d2l-v2/pytorch/chapter_preliminaries/autograd.ipynb Cell 13\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e76696469612d637564612d636f6e6461227d/root/workspace/d2l-v2/pytorch/chapter_preliminaries/autograd.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39msum()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e76696469612d637564612d636f6e6461227d/root/workspace/d2l-v2/pytorch/chapter_preliminaries/autograd.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m y\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e76696469612d637564612d636f6e6461227d/root/workspace/d2l-v2/pytorch/chapter_preliminaries/autograd.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m y\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f6e76696469612d637564612d636f6e6461227d/root/workspace/d2l-v2/pytorch/chapter_preliminaries/autograd.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m x\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    493\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    494\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[39m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m     tensors,\n\u001b[1;32m    253\u001b[0m     grad_tensors_,\n\u001b[1;32m    254\u001b[0m     retain_graph,\n\u001b[1;32m    255\u001b[0m     create_graph,\n\u001b[1;32m    256\u001b[0m     inputs,\n\u001b[1;32m    257\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    258\u001b[0m     accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    259\u001b[0m )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "x = torch.arange(4.0)\n",
    "x.requires_grad_(True)\n",
    "y = 2 * x\n",
    "y = y.sum()\n",
    "y.backward()\n",
    "y.backward()\n",
    "\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640dee7e",
   "metadata": {
    "origin_pos": 30
   },
   "source": [
    "## 非标量变量的反向传播\n",
    "\n",
    "当`y`不是标量时，向量`y`关于向量`x`的导数的最自然解释是一个矩阵。\n",
    "对于高阶和高维的`y`和`x`，求导的结果可以是一个高阶张量。\n",
    "\n",
    "然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括[**深度学习中**]），\n",
    "但当调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。\n",
    "这里(**，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。**)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de02a306",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.899324Z",
     "iopub.status.busy": "2022-12-07T16:37:10.898840Z",
     "iopub.status.idle": "2022-12-07T16:37:10.904849Z",
     "shell.execute_reply": "2022-12-07T16:37:10.904154Z"
    },
    "origin_pos": 32,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。\n",
    "# 本例只想求偏导数的和，所以传递一个1的梯度是合适的\n",
    "x.grad.zero_()\n",
    "y = x * x\n",
    "# 等价于y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca55ef50",
   "metadata": {
    "origin_pos": 35
   },
   "source": [
    "## 分离计算\n",
    "\n",
    "有时，我们希望[**将某些计算移动到记录的计算图之外**]。\n",
    "例如，假设`y`是作为`x`的函数计算的，而`z`则是作为`y`和`x`的函数计算的。\n",
    "想象一下，我们想计算`z`关于`x`的梯度，但由于某种原因，希望将`y`视为一个常数，\n",
    "并且只考虑到`x`在`y`被计算后发挥的作用。\n",
    "\n",
    "这里可以分离`y`来返回一个新变量`u`，该变量与`y`具有相同的值，\n",
    "但丢弃计算图中如何计算`y`的任何信息。\n",
    "换句话说，梯度不会向后流经`u`到`x`。\n",
    "因此，下面的反向传播函数计算`z=u*x`关于`x`的偏导数，同时将`u`作为常数处理，\n",
    "而不是`z=x*x*x`关于`x`的偏导数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0d0a164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.908385Z",
     "iopub.status.busy": "2022-12-07T16:37:10.907775Z",
     "iopub.status.idle": "2022-12-07T16:37:10.915808Z",
     "shell.execute_reply": "2022-12-07T16:37:10.914379Z"
    },
    "origin_pos": 37,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y = x * x\n",
    "u = y.detach()\n",
    "z = u * x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad == u"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d753da",
   "metadata": {
    "origin_pos": 40
   },
   "source": [
    "由于记录了`y`的计算结果，我们可以随后在`y`上调用反向传播，\n",
    "得到`y=x*x`关于的`x`的导数，即`2*x`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16899140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.920202Z",
     "iopub.status.busy": "2022-12-07T16:37:10.919752Z",
     "iopub.status.idle": "2022-12-07T16:37:10.927012Z",
     "shell.execute_reply": "2022-12-07T16:37:10.925890Z"
    },
    "origin_pos": 42,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad == 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8831f3d",
   "metadata": {
    "origin_pos": 45
   },
   "source": [
    "## Python控制流的梯度计算\n",
    "\n",
    "使用自动微分的一个好处是：\n",
    "[**即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度**]。\n",
    "在下面的代码中，`while`循环的迭代次数和`if`语句的结果都取决于输入`a`的值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4eb430b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.930293Z",
     "iopub.status.busy": "2022-12-07T16:37:10.929875Z",
     "iopub.status.idle": "2022-12-07T16:37:10.935285Z",
     "shell.execute_reply": "2022-12-07T16:37:10.934140Z"
    },
    "origin_pos": 47,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while b.norm() < 1000:\n",
    "        b = b * 2\n",
    "    if b.sum() > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ae43cf",
   "metadata": {
    "origin_pos": 50
   },
   "source": [
    "让我们计算梯度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4251a67a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.938498Z",
     "iopub.status.busy": "2022-12-07T16:37:10.937961Z",
     "iopub.status.idle": "2022-12-07T16:37:10.946161Z",
     "shell.execute_reply": "2022-12-07T16:37:10.945110Z"
    },
    "origin_pos": 52,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [],
   "source": [
    "a = torch.randn(size=(), requires_grad=True)\n",
    "d = f(a)\n",
    "d.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b607640",
   "metadata": {
    "origin_pos": 55
   },
   "source": [
    "我们现在可以分析上面定义的`f`函数。\n",
    "请注意，它在其输入`a`中是分段线性的。\n",
    "换言之，对于任何`a`，存在某个常量标量`k`，使得`f(a)=k*a`，其中`k`的值取决于输入`a`，因此可以用`d/a`验证梯度是否正确。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd3e9d01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-07T16:37:10.949650Z",
     "iopub.status.busy": "2022-12-07T16:37:10.949215Z",
     "iopub.status.idle": "2022-12-07T16:37:10.956034Z",
     "shell.execute_reply": "2022-12-07T16:37:10.954996Z"
    },
    "origin_pos": 57,
    "tab": [
     "pytorch"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad == d / a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74238334",
   "metadata": {
    "origin_pos": 60
   },
   "source": [
    "## 小结\n",
    "\n",
    "* 深度学习框架可以自动计算导数：我们首先将梯度附加到想要对其计算偏导数的变量上，然后记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。\n",
    "\n",
    "## 练习\n",
    "\n",
    "1. 为什么计算二阶导数比一阶导数的开销要更大？\n",
    "1. 在运行反向传播函数之后，立即再次运行它，看看会发生什么。\n",
    "1. 在控制流的例子中，我们计算`d`关于`a`的导数，如果将变量`a`更改为随机向量或矩阵，会发生什么？\n",
    "1. 重新设计一个求控制流梯度的例子，运行并分析结果。\n",
    "1. 使$f(x)=\\sin(x)$，绘制$f(x)$和$\\frac{df(x)}{dx}$的图像，其中后者不使用$f'(x)=\\cos(x)$。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "461c1e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"240.982812pt\" height=\"169.678125pt\" viewBox=\"0 0 240.982812 169.678125\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2023-10-18T12:27:30.407761</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.7.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M -0 169.678125 \n",
       "L 240.982813 169.678125 \n",
       "L 240.982813 0 \n",
       "L -0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 38.482813 145.8 \n",
       "L 233.782813 145.8 \n",
       "L 233.782813 7.2 \n",
       "L 38.482813 7.2 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 65.585985 145.8 \n",
       "L 65.585985 7.2 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_2\">\n",
       "      <defs>\n",
       "       <path id=\"m4b1c7be96e\" d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4b1c7be96e\" x=\"65.585985\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −5.0 -->\n",
       "      <g transform=\"translate(53.444579 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-2212\" d=\"M 678 2272 \n",
       "L 4684 2272 \n",
       "L 4684 1741 \n",
       "L 678 1741 \n",
       "L 678 2272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \n",
       "L 3169 4666 \n",
       "L 3169 4134 \n",
       "L 1269 4134 \n",
       "L 1269 2991 \n",
       "Q 1406 3038 1543 3061 \n",
       "Q 1681 3084 1819 3084 \n",
       "Q 2600 3084 3056 2656 \n",
       "Q 3513 2228 3513 1497 \n",
       "Q 3513 744 3044 326 \n",
       "Q 2575 -91 1722 -91 \n",
       "Q 1428 -91 1123 -41 \n",
       "Q 819 9 494 109 \n",
       "L 494 744 \n",
       "Q 775 591 1075 516 \n",
       "Q 1375 441 1709 441 \n",
       "Q 2250 441 2565 725 \n",
       "Q 2881 1009 2881 1497 \n",
       "Q 2881 1984 2565 2268 \n",
       "Q 2250 2553 1709 2553 \n",
       "Q 1456 2553 1204 2497 \n",
       "Q 953 2441 691 2322 \n",
       "L 691 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \n",
       "L 1344 794 \n",
       "L 1344 0 \n",
       "L 684 0 \n",
       "L 684 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \n",
       "Q 1547 4250 1301 3770 \n",
       "Q 1056 3291 1056 2328 \n",
       "Q 1056 1369 1301 889 \n",
       "Q 1547 409 2034 409 \n",
       "Q 2525 409 2770 889 \n",
       "Q 3016 1369 3016 2328 \n",
       "Q 3016 3291 2770 3770 \n",
       "Q 2525 4250 2034 4250 \n",
       "z\n",
       "M 2034 4750 \n",
       "Q 2819 4750 3233 4129 \n",
       "Q 3647 3509 3647 2328 \n",
       "Q 3647 1150 3233 529 \n",
       "Q 2819 -91 2034 -91 \n",
       "Q 1250 -91 836 529 \n",
       "Q 422 1150 422 2328 \n",
       "Q 422 3509 836 4129 \n",
       "Q 1250 4750 2034 4750 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 101.095076 145.8 \n",
       "L 101.095076 7.2 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4b1c7be96e\" x=\"101.095076\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- −2.5 -->\n",
       "      <g transform=\"translate(88.95367 160.398438) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \n",
       "L 3431 531 \n",
       "L 3431 0 \n",
       "L 469 0 \n",
       "L 469 531 \n",
       "Q 828 903 1448 1529 \n",
       "Q 2069 2156 2228 2338 \n",
       "Q 2531 2678 2651 2914 \n",
       "Q 2772 3150 2772 3378 \n",
       "Q 2772 3750 2511 3984 \n",
       "Q 2250 4219 1831 4219 \n",
       "Q 1534 4219 1204 4116 \n",
       "Q 875 4013 500 3803 \n",
       "L 500 4441 \n",
       "Q 881 4594 1212 4672 \n",
       "Q 1544 4750 1819 4750 \n",
       "Q 2544 4750 2975 4387 \n",
       "Q 3406 4025 3406 3419 \n",
       "Q 3406 3131 3298 2873 \n",
       "Q 3191 2616 2906 2266 \n",
       "Q 2828 2175 2409 1742 \n",
       "Q 1991 1309 1228 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-32\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 136.604167 145.8 \n",
       "L 136.604167 7.2 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4b1c7be96e\" x=\"136.604167\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(128.652605 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 172.113258 145.8 \n",
       "L 172.113258 7.2 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4b1c7be96e\" x=\"172.113258\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 2.5 -->\n",
       "      <g transform=\"translate(164.161695 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-32\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 207.622349 145.8 \n",
       "L 207.622349 7.2 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m4b1c7be96e\" x=\"207.622349\" y=\"145.8\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 5.0 -->\n",
       "      <g transform=\"translate(199.670786 160.398438) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-35\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 38.482813 139.500616 \n",
       "L 233.782813 139.500616 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_12\">\n",
       "      <defs>\n",
       "       <path id=\"m3a120041c7\" d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3a120041c7\" x=\"38.482813\" y=\"139.500616\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- −1.0 -->\n",
       "      <g transform=\"translate(7.2 143.299835) scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-31\" d=\"M 794 531 \n",
       "L 1825 531 \n",
       "L 1825 4091 \n",
       "L 703 3866 \n",
       "L 703 4441 \n",
       "L 1819 4666 \n",
       "L 2450 4666 \n",
       "L 2450 531 \n",
       "L 3481 531 \n",
       "L 3481 0 \n",
       "L 794 0 \n",
       "L 794 531 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-31\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"179.199219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 38.482813 108.000462 \n",
       "L 233.782813 108.000462 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3a120041c7\" x=\"38.482813\" y=\"108.000462\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- −0.5 -->\n",
       "      <g transform=\"translate(7.2 111.799681) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-2212\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"83.789062\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"147.412109\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"179.199219\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 38.482813 76.500308 \n",
       "L 233.782813 76.500308 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3a120041c7\" x=\"38.482813\" y=\"76.500308\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0.0 -->\n",
       "      <g transform=\"translate(15.579688 80.299527) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 38.482813 45.000154 \n",
       "L 233.782813 45.000154 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_18\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3a120041c7\" x=\"38.482813\" y=\"45.000154\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0.5 -->\n",
       "      <g transform=\"translate(15.579688 48.799373) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-30\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 38.482813 13.5 \n",
       "L 233.782813 13.5 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #b0b0b0; stroke-width: 0.8; stroke-linecap: square\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_20\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#m3a120041c7\" x=\"38.482813\" y=\"13.5\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1.0 -->\n",
       "      <g transform=\"translate(15.579688 17.299219) scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-31\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path d=\"M 47.360085 76.500319 \n",
       "L 48.780448 70.210789 \n",
       "L 50.20081 63.984102 \n",
       "L 51.621179 57.882443 \n",
       "L 53.041541 51.966837 \n",
       "L 54.461903 46.29636 \n",
       "L 55.882266 40.927672 \n",
       "L 57.302628 35.914411 \n",
       "L 58.722997 31.306654 \n",
       "L 60.143359 27.150474 \n",
       "L 61.563722 23.487382 \n",
       "L 62.984091 20.353964 \n",
       "L 64.404453 17.781555 \n",
       "L 65.824815 15.795845 \n",
       "L 67.245177 14.416671 \n",
       "L 68.66554 13.657816 \n",
       "L 70.085909 13.526864 \n",
       "L 71.506271 14.025122 \n",
       "L 72.926633 15.147608 \n",
       "L 74.347002 16.883118 \n",
       "L 75.767365 19.214299 \n",
       "L 77.187727 22.11786 \n",
       "L 78.608089 25.564789 \n",
       "L 80.028455 29.520659 \n",
       "L 81.448814 33.945915 \n",
       "L 82.869176 38.796369 \n",
       "L 84.289542 44.023562 \n",
       "L 85.709904 49.575237 \n",
       "L 87.13027 55.395952 \n",
       "L 88.550632 61.427522 \n",
       "L 89.970994 67.609693 \n",
       "L 91.39136 73.880711 \n",
       "L 92.811726 80.177904 \n",
       "L 94.232088 86.438336 \n",
       "L 95.652454 92.599486 \n",
       "L 97.072816 98.599763 \n",
       "L 98.493182 104.379243 \n",
       "L 99.913544 109.880154 \n",
       "L 101.333906 115.047543 \n",
       "L 102.754272 119.829794 \n",
       "L 104.174634 124.179102 \n",
       "L 105.594996 128.052015 \n",
       "L 107.015362 131.409854 \n",
       "L 108.435724 134.219045 \n",
       "L 109.856088 136.451533 \n",
       "L 111.276452 138.085007 \n",
       "L 112.696816 139.103149 \n",
       "L 114.11718 139.495783 \n",
       "L 115.537542 139.258986 \n",
       "L 116.957906 138.395126 \n",
       "L 118.37827 136.91283 \n",
       "L 119.798633 134.826918 \n",
       "L 121.218997 132.158225 \n",
       "L 122.639361 128.933411 \n",
       "L 124.059725 125.184706 \n",
       "L 125.480088 120.949564 \n",
       "L 126.900452 116.270298 \n",
       "L 128.320816 111.193666 \n",
       "L 129.741179 105.770388 \n",
       "L 131.161543 100.054651 \n",
       "L 132.581906 94.103568 \n",
       "L 134.00227 87.9766 \n",
       "L 135.422634 81.734964 \n",
       "L 136.842997 75.441025 \n",
       "L 138.26336 69.157672 \n",
       "L 139.683724 62.947682 \n",
       "L 141.104088 56.873107 \n",
       "L 142.524451 50.994639 \n",
       "L 143.944815 45.371014 \n",
       "L 145.365178 40.058424 \n",
       "L 146.785542 35.10995 \n",
       "L 148.205906 30.575034 \n",
       "L 149.626269 26.498989 \n",
       "L 151.046633 22.922538 \n",
       "L 152.466997 19.881421 \n",
       "L 153.88736 17.406021 \n",
       "L 155.307724 15.521072 \n",
       "L 156.728088 14.245405 \n",
       "L 158.148452 13.591771 \n",
       "L 159.568816 13.566695 \n",
       "L 160.989178 14.170434 \n",
       "L 162.409542 15.396951 \n",
       "L 163.829906 17.233992 \n",
       "L 165.25027 19.663204 \n",
       "L 166.670632 22.660312 \n",
       "L 168.090994 26.195369 \n",
       "L 169.51136 30.233064 \n",
       "L 170.931722 34.733035 \n",
       "L 172.352088 39.650345 \n",
       "L 173.77245 44.935836 \n",
       "L 175.192816 50.53672 \n",
       "L 176.613178 56.397012 \n",
       "L 178.033544 62.458181 \n",
       "L 179.453906 68.659642 \n",
       "L 180.874268 74.939443 \n",
       "L 182.294634 81.234856 \n",
       "L 183.714996 87.482947 \n",
       "L 185.135359 93.621303 \n",
       "L 186.555724 99.588608 \n",
       "L 187.976087 105.325206 \n",
       "L 189.396452 110.77381 \n",
       "L 190.816815 115.87995 \n",
       "L 192.237177 120.592622 \n",
       "L 193.657542 124.864752 \n",
       "L 195.077905 128.653629 \n",
       "L 196.498267 131.921405 \n",
       "L 197.918629 134.635438 \n",
       "L 199.338998 136.768611 \n",
       "L 200.759361 138.299592 \n",
       "L 202.179723 139.213098 \n",
       "L 203.600085 139.5 \n",
       "L 205.020448 139.157429 \n",
       "L 206.440817 138.188805 \n",
       "L 207.861179 136.603814 \n",
       "L 209.281541 134.418291 \n",
       "L 210.701903 131.654071 \n",
       "L 212.122272 128.338755 \n",
       "L 213.542635 124.505504 \n",
       "L 214.962997 120.192601 \n",
       "L 216.383359 115.443141 \n",
       "L 217.803722 110.304575 \n",
       "L 219.224091 104.828225 \n",
       "L 220.644453 99.068857 \n",
       "L 222.064815 93.083991 \n",
       "L 223.485177 86.933427 \n",
       "L 224.90554 80.678619 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_22\">\n",
       "    <path d=\"M 47.360085 13.5 \n",
       "L 48.780448 13.814738 \n",
       "L 50.20081 14.755807 \n",
       "L 51.621179 16.313814 \n",
       "L 53.041541 18.473179 \n",
       "L 54.461903 21.21233 \n",
       "L 55.882266 24.503902 \n",
       "L 57.302628 28.315002 \n",
       "L 58.722997 32.607571 \n",
       "L 60.143359 37.338684 \n",
       "L 61.563722 42.461087 \n",
       "L 62.984091 47.923624 \n",
       "L 64.404453 53.671665 \n",
       "L 65.824815 59.6478 \n",
       "L 67.245177 65.792321 \n",
       "L 68.66554 72.043831 \n",
       "L 70.085909 78.3399 \n",
       "L 71.506271 84.617558 \n",
       "L 72.926633 90.814111 \n",
       "L 74.347002 96.867673 \n",
       "L 75.767365 102.717704 \n",
       "L 77.187727 108.305779 \n",
       "L 78.608089 113.576066 \n",
       "L 80.028455 118.475915 \n",
       "L 81.448814 122.956337 \n",
       "L 82.869176 126.972597 \n",
       "L 84.289542 130.484561 \n",
       "L 85.709904 133.457129 \n",
       "L 87.13027 135.860607 \n",
       "L 88.550632 137.670972 \n",
       "L 89.970994 138.87014 \n",
       "L 91.39136 139.446129 \n",
       "L 92.811726 139.393186 \n",
       "L 94.232088 138.711836 \n",
       "L 95.652454 137.408891 \n",
       "L 97.072816 135.497367 \n",
       "L 98.493182 132.996358 \n",
       "L 99.913544 129.930866 \n",
       "L 101.333906 126.331517 \n",
       "L 102.754272 122.234259 \n",
       "L 104.174634 117.680053 \n",
       "L 105.594996 112.714395 \n",
       "L 107.015362 107.386884 \n",
       "L 108.435724 101.750778 \n",
       "L 109.856088 95.862372 \n",
       "L 111.276452 89.780505 \n",
       "L 112.696816 83.565946 \n",
       "L 114.11718 77.280791 \n",
       "L 115.537542 70.987844 \n",
       "L 116.957906 64.749969 \n",
       "L 118.37827 58.629498 \n",
       "L 119.798633 52.687595 \n",
       "L 121.218997 46.983613 \n",
       "L 122.639361 41.574554 \n",
       "L 124.059725 36.514459 \n",
       "L 125.480088 31.853893 \n",
       "L 126.900452 27.63942 \n",
       "L 128.320816 23.913144 \n",
       "L 129.741179 20.712306 \n",
       "L 131.161543 18.068881 \n",
       "L 132.581906 16.009282 \n",
       "L 134.00227 14.554093 \n",
       "L 135.422634 13.717849 \n",
       "L 136.842997 13.508907 \n",
       "L 138.26336 13.929352 \n",
       "L 139.683724 14.974985 \n",
       "L 141.104088 16.63536 \n",
       "L 142.524451 18.893886 \n",
       "L 143.944815 21.728 \n",
       "L 145.365178 25.109376 \n",
       "L 146.785542 29.004234 \n",
       "L 148.205906 33.373658 \n",
       "L 149.626269 38.173986 \n",
       "L 151.046633 43.357263 \n",
       "L 152.466997 48.871694 \n",
       "L 153.88736 54.662173 \n",
       "L 155.307724 60.670859 \n",
       "L 156.728088 66.837707 \n",
       "L 158.148452 73.101101 \n",
       "L 159.568816 79.398458 \n",
       "L 160.989178 85.666851 \n",
       "L 162.409542 91.843662 \n",
       "L 163.829906 97.867169 \n",
       "L 165.25027 103.677184 \n",
       "L 166.670632 109.21565 \n",
       "L 168.090994 114.427233 \n",
       "L 169.51136 119.259877 \n",
       "L 170.931722 123.665272 \n",
       "L 172.352088 127.599419 \n",
       "L 173.77245 131.022991 \n",
       "L 175.192816 133.901798 \n",
       "L 176.613178 136.207061 \n",
       "L 178.033544 137.915756 \n",
       "L 179.453906 139.01081 \n",
       "L 180.874268 139.481277 \n",
       "L 182.294634 139.322458 \n",
       "L 183.714996 138.535947 \n",
       "L 185.135359 137.129594 \n",
       "L 186.555724 135.117451 \n",
       "L 187.976087 132.519628 \n",
       "L 189.396452 129.362072 \n",
       "L 190.816815 125.676344 \n",
       "L 192.237177 121.499271 \n",
       "L 193.657542 116.872569 \n",
       "L 195.077905 111.842492 \n",
       "L 196.498267 106.459291 \n",
       "L 197.918629 100.776749 \n",
       "L 199.338998 94.851616 \n",
       "L 200.759361 88.743151 \n",
       "L 202.179723 82.51236 \n",
       "L 203.600085 76.221499 \n",
       "L 205.020448 69.933423 \n",
       "L 206.440817 63.710932 \n",
       "L 207.861179 57.616259 \n",
       "L 209.281541 51.710267 \n",
       "L 210.701903 46.051968 \n",
       "L 212.122272 40.697874 \n",
       "L 213.542635 35.701534 \n",
       "L 214.962997 31.112841 \n",
       "L 216.383359 26.977642 \n",
       "L 217.803722 23.337257 \n",
       "L 219.224091 20.228044 \n",
       "L 220.644453 17.681098 \n",
       "L 222.064815 15.721854 \n",
       "L 223.485177 14.36989 \n",
       "L 224.90554 13.63871 \n",
       "\" clip-path=\"url(#p7c69bfabad)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #bf00bf; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 38.482813 145.8 \n",
       "L 38.482813 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 233.782813 145.8 \n",
       "L 233.782813 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 38.482813 145.8 \n",
       "L 233.782813 145.8 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 38.482813 7.2 \n",
       "L 233.782813 7.2 \n",
       "\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p7c69bfabad\">\n",
       "   <rect x=\"38.482813\" y=\"7.2\" width=\"195.3\" height=\"138.6\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 350x250 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from d2l import torch as d2l\n",
    "x = torch.arange(-2 * torch.pi, 2 * torch.pi, 0.1)\n",
    "x.requires_grad_(True)\n",
    "\n",
    "y = torch.sin(x)\n",
    "\n",
    "z = y.sum()\n",
    "\n",
    "z.backward()\n",
    "# d2l.plot(x.detach().numpy(), x.grad)\n",
    "d2l.plot(x.detach().numpy(), [y.detach().numpy(), x.grad])\n",
    "\n",
    "# x.grad\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba845e3d",
   "metadata": {
    "origin_pos": 62,
    "tab": [
     "pytorch"
    ]
   },
   "source": [
    "[Discussions](https://discuss.d2l.ai/t/1759)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
